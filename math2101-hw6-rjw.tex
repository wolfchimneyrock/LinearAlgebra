\documentclass{letter}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{bm}
\usepackage[letterpaper,portrait,left=2cm,right=2cm,top=3.5cm,bottom=2cm]{geometry}
\pagestyle{fancy}

\fancyhf{}
\rhead{Robert Wagner\\July 7, 2016}
\lhead{Math 2101\\Assignment 6 revised}
\newcounter{question}
\setcounter{question}{0}
\usepackage{amsmath,amsthm}
\usepackage{amssymb}
\usepackage{tikz}
\usetikzlibrary{arrows}


% magnitude bars
\newcommand{\norm}[1]{\lvert #1 \rvert}

% explicit vector
\newcommand{\Ve}[1]{\langle #1 \rangle}

% named vector
\newcommand{\Vn}[1]{\vec{#1}}

% a line with an arrow above
\newcommand{\Line}[1]{\overrightarrow{#1}}

% equals with question mark above
\newcommand{\?}{\stackrel{?}{=}}

% formatting for questions
\newcommand\Que[1]{%
   \leavevmode\noindent
   #1
}

% formatting for answers
\newcommand\Ans[2][]{%
   \leavevmode\noindent
   {
       \begin{mdframed}[backgroundcolor=blue!10]
       #2
       \end{mdframed}
   }
}

% this is like align but squashed     
\newenvironment{salign}
 {\par$\!\aligned}
 {\endaligned$\par}

% a matrix, parameter is column count
\newenvironment{Mat}[1]{%
  \left[\begin{array}{*{#1}{r}}
}{%
  \end{array}\right]
}
% a matrix, parameter is column count centered
\newenvironment{Cmat}[1]{%
  \left[\begin{array}{*{#1}{c}}
}{%
  \end{array}\right]
}

% an augmented matrix, with one augmented column
\newenvironment{Amat}[1]{%
  \left[\begin{array}{@{}*{#1}{r}|r@{}}
}{%
  \end{array}\right]
}
% an augmented matrix with n columns and n augmented columns
\newenvironment{Amat2}[1]{%
  \left[\begin{array}{@{~}*{#1}{r}| @{~~}*{#1}{r}}
}{%
  \end{array}\right]
}
% an augmented matrix with n columns and m augmented columns
\newenvironment{Amat3}[2]{%
  \left[\begin{array}{@{~}*{#1}{r}| @{~~}*{#2}{r}}
}{%
  \end{array}\right]
}


\begin{document}


\begin{enumerate}
    \item Determine whether the mapping is linear.  Show your work.
    \begin{enumerate}
    \item The derivative mapping $D:f\to f^\prime$
    \Ans{
       Let $\mathbb{F}$\ be a field, 
       let $\mathbb{X}$\ be the vector space of functions $\mathbb{F}\to\mathbb{F}$, 
       let $x\in\mathbb{F}$,
       let $f,g\in \mathbb{X}$, 
       and let $c\in\mathbb{R}$.\\
       Since by definition of derivative $\frac{d}{dx}\left(f(x)+g(x)\right) = \frac{d}{dx}f(x) + \frac{d}{dx}g(x)$
       \begin{align*}
         D(\Vn{f}+\Vn{g}) &= D\Vn{f} + D\Vn{g}
       \shortintertext{Thus the additive property is retained.}
       \shortintertext{Since by definition of derivative $\frac{d}{dx}cf(x) = c\frac{d}{dx}f(x)$}
         D(c\Vn{f}) &= cD\Vn{f} 
       \end{align*}
       Thus the scalar multiplication property is retained, and D is a linear mapping.
    }
    \item The scalar mapping $S:x\to cx$. (Assume $c\in\mathbb{R}$)
    \Ans{
        Let $x_1, x_2\in \mathbb{F}^n$\ for some $n\in\mathbb{N}$\ (an arbitrary vector field).
        \begin{align*}
            S(x_1) &= cx_1 \\
            S(x_2) &= cx_2 \\
            S(x_1)+S(x_2) &= cx_1+cx_2\\
            S(x_1+x_2) &= c(x_1+x_2) = cx_1+cx_2 = S(x_1)+S(x_2)
        \shortintertext{Thus the additive property is retained. Now let $d\in\mathbb{R}$.}
            dS(x_1) &= d(cx_1) = cdx_1\\
            S(dx_1) &= c(dx_1) = cdx_1 = d(cx_1) = 
            dS(x_1)
        \end{align*}  
        Thus the scalar multiplication property is retained, and $S$\ is a linear mapping.
    }    
    \item The inverse mapping $I:x\to \frac{1}{x}$, where $x\not = 0$. 
    \Ans{
        This is not a linear mapping.  Counterexample:  Let $x_1=2, x_2=3$.  
        \begin{align*}
            I(x_1)&=\frac{1}{x_1}=\frac{1}{2}\\
            I(x_2)&=\frac{1}{x_2}=\frac{1}{3}\\
            I(x_1)+I(x_2)&=\frac{1}{2}+\frac{1}{3} = \frac{5}{6}\\
            I(x_1+x_2)&=\frac{1}{x_1+x_2}=\frac{1}{2+3}=\frac{1}{5} \not = \frac{5}{6}
         \end{align*}
         Thus the mapping $I$\ does not retain vector addition and is not a linear mapping.
    }    
    \item The log mapping $L:x\to\log x$, where $x>0$.
    \Ans{
        This is not a linear mapping.  Counterexample: Let $x_1=1, x_2=1$.
        \begin{align*}
            L(x_1) &= \log 1 = 0 \\
            L(x_2) &= \log 1 = 0 \\
            L(x_1) + L(x_2) &= 0 + 0 = 0 \\
            L(x_1+x_2) &= L(2) = \log 2 \not = 0 
        \end{align*}
        Thus the mapping $L$\ does not retain vector addition and is not a linear mapping.
    }
    \newpage
    \item Matrix multiplication: $M:x\to Mx$, where $M$\ is a specific matrix and $x$\ has the right dimension to be multiplied by $M$.
    \Ans{
      Let $\Vn{x}_1,\Vn{x}_2\in \mathbb{F}^n$\ for some $n\in\mathbb{N}$\ (an arbitrary vector field),
      and let $m_i$\ be the $i$th row of $M$\ for $i\in\{1\cdots n\}$.
      \begin{align*}
          M\Vn{x}_1 &= \begin{Mat}{1} m_1\cdot \Vn{x}_1\\ m_2\cdot\Vn{x}_1 \\ \vdots \\ m_n\cdot\Vn{x}_1 \end{Mat}, ~~~
          M\Vn{x}_2 = \begin{Mat}{1} m_1\cdot \Vn{x}_2\\ m_2\cdot\Vn{x}_2 \\ \vdots \\ m_n\cdot\Vn{x}_2 \end{Mat} \\
          M\Vn{x}_1 + M\Vn{x}_2 &= \begin{Mat}{1} m_1\cdot \Vn{x}_1 +  m_1\cdot \Vn{x}_2 \\ 
                                                  m_2\cdot\Vn{x}_1 + m_2\cdot\Vn{x}_2 \\
                                                  \vdots \\ 
                                                  m_n\cdot\Vn{x}_1 + m_n\cdot\Vn{x}_2\end{Mat}
                                = \begin{Mat}{1} m_1\cdot(\Vn{x}_1 + \Vn{x}_2) \\
                                                  m_2\cdot(\Vn{x}_1 + \Vn{x}_2) \\
                                                  \vdots \\
                                                  m_n\cdot(\Vn{x}_1 + \Vn{x}_2) \end{Mat} \\
                                &= M(\Vn{x}_1+\Vn{x}_2)
          \shortintertext{Thus the additive property is retained.  Now let $c\in\mathbb{R}$.}
          M(c\Vn{X}_1) &= \begin{Mat}{1} m_1\cdot(c\Vn{x}_1) \\ m_2\cdot(c\Vn{x}_1) \\ \vdots \\ m_n\cdot(c\Vn{x}_1) \end{Mat} 
                        = \begin{Mat}{1} c(m_1\cdot\Vn{x}_1) \\ c(m_2\cdot\Vn{x}_1) \\ \vdots \\ c(m_n\cdot(\Vn{x}_1) \end{Mat} \\
                       &= c\begin{Mat}{1} m_1\cdot\Vn{x}_1 \\ m_2\cdot\Vn{x}_1 \\ \vdots \\ m_n\cdot\Vn{x}_1 \end{Mat}
                        = cM\Vn{x}_1
      \end{align*}
      Thus the scalar multiplication property is retained, and M is a linear operator.
    }
    \end{enumerate}
    ~\\     
    \item 
        A permutation of $n$\ objects is a rearrangement of the $n$\ objects.  A permutation matrix is a matrix whose entries are either $0$\ or $1$, with the added restriction that each column and each row consists of a single $1$, with the other entries being $0$.
    \begin{enumerate}[label=(\alph*)]
    \item \Que{
        Let $P$\ be a $n\times m$\ matrix.  What restrictions, if any, must we impose on $n,m$\ if we want $P$\ to be a permutation matrix? 
        Prove your answer.        
    }
    \Ans{
       Let $\Vn{v} \in \mathbb{R}^n$\ be an ordered list of objects to be permuted.  By the definition of matrix multiplication, $P\Vn{v} \in \mathbb{R}^m$.  By the definition of permutation, The original and permuted list are to be reorderings of each other, with the same number of elements.  Thus it must be the case that $m=n$, and the matrix must be square.
    }
    \item \Que{
        Let $P$\ be a permutation matrix and $\Vn{x}$\ a vector of the appropriate size.  Explain why $P\Vn{x}$\ is a permutation (rearrangement) of the components of $\Vn{x}$.
    }
    \Ans{
        Let $\Vn{x}^\prime=P\Vn{x}$, let $P_j$\ for some $j\in \{1\cdots n\}$\ be a row of $P$, let $k\in\{1\cdots n\}$\ be the row number of the non-zero element of $P_j$, and let $x_k$\ be the $k$th element of $\Vn{x}$.  By the definition of matrix multiplication, the $j$th element of $\Vn{x}^\prime$\ will equal $x_k$\ since $P_{jk}=1$\ and all other elements of $P_j=0$.  Since each column of $P$ contains only one non-zero entry, we are guaranteed that $x_k$\ will not be represented in any other entry of $\Vn{x}^\prime$.
    }
    \newpage
    \item \Que{
        Explain why $P^k=I$\ for some $k$.
    }
    \Ans{
       The permutation operation applied successively to a vector forms a cyclical chain of permutations that eventually produce the original vector.  Since the specific permutation is fixed,  there can be no more than $n$\ unique permutations produced from an original vector of size $n$.  Thus for some $k\leq n$ such that $k$\ is the number of unique permutations in the cycle, $P^k=I$\ 
    }
    \item \Que{
      Find a permutation matrix for the sestina.  That is, find $P$\ so that
      \begin{align*}
          P\begin{Mat}{1} A\\B\\C\\D\\E\\F \end{Mat} &= \begin{Mat}{1} F\\A\\E\\B\\D\\C \end{Mat}
      \end{align*}
    }
    \Ans{
    \begin{align*}
      P = \begin{Mat}{6} 0 & 0 & 0 & 0 & 0 & 1 \\
                         1 & 0 & 0 & 0 & 0 & 0 \\
                         0 & 0 & 0 & 0 & 1 & 0 \\
                         0 & 1 & 0 & 0 & 0 & 0 \\
                         0 & 0 & 0 & 1 & 0 & 0 \\
                         0 & 0 & 1 & 0 & 0 & 0 \end{Mat}
    \end{align*}
    }
    \item \Que{
       The sestina has six stanzas.  You have just found the first two stanzas.  The remaining stanzas are found by applying $P$\ repeatedly.  Find the rhythm scheme for the remaining stanzas.  Can you see why a sestina has six and not five or seven stanzas?
    }
    \Ans{
      \begin{align*}
        \Vn{s}    &= \begin{Mat}{6} A & B & C & D & E & F \end{Mat}^T \\
        P\Vn{s}   &= \begin{Mat}{6} F & A & E & B & D & C \end{Mat}^T \\
        P^2\Vn{s} &= \begin{Mat}{6} C & F & D & A & B & E \end{Mat}^T \\
        P^3\Vn{s} &= \begin{Mat}{6} E & C & B & F & A & D \end{Mat}^T \\
        P^4\Vn{s} &= \begin{Mat}{6} D & E & A & C & F & B \end{Mat}^T \\
        P^5\Vn{s} &= \begin{Mat}{6} B & D & F & E & C & A \end{Mat}^T \\
        P^6\Vn{s} &= \begin{Mat}{6} A & B & C & D & E & F \end{Mat}^T = \Vn{s}                
      \end{align*}
      Thus we see that $P^6=I$\ and the cycle has six stanzas so that it can be repeated ad infinitum with no feeling of discontinuity for the audience.
    }
    \newpage
    \item \Que{
        Suppose you want to invent a new poetic form similar to a sestina, based on five terminal words $A,B,C,D,E$.  If possible, construct a permutation matrix that will give this form two stanzas of five lines. 
    }
    \Ans{
    We want to find $P$ such that
    \begin{align*}
        P^2 &= I \\
        P &= P^{-1}
        \shortintertext{My intuition is that this will be true if $P=P^T$}
        P &= \begin{Mat}{5} 0 & 0 & 1 & 0 & 0 \\
                            0 & 0 & 0 & 0 & 1 \\
                            1 & 0 & 0 & 0 & 0 \\
                            0 & 0 & 0 & 1 & 0 \\
                            0 & 1 & 0 & 0 & 0 \end{Mat}
        \shortintertext{Verify:}
        \Vn{s}    &= \begin{Mat}{5} A & B & C & D & E \end{Mat}^T \\
        P\Vn{s}   &= \begin{Mat}{5} C & E & A & D & B \end{Mat}^T \\
        P^2\Vn{s} &= \begin{Mat}{5} A & B & C & D & E \end{Mat}^T
                   = \Vn{s}
    \end{align*}
    Observation:  Since there are an odd number of words and an even number of stanzas, one word will always remain in its original place in the rhythm since it has no word left to swap with.
    }
    \item \Que{
        Suppose you decide two stanzas isn't interesting enough.  If possible, construct a permutation matrix that will give this form six stanzas of five lines.
    }
    \Ans{
      To find the original Sestina transformation for $n=6$(words) and $k=6$(stanzas), we generated unique orderings $p_k$\ of $\{1,\cdots,n\}$\ with no duplicates:
      \begin{align*}
          p_1 &= (2,4,5,3,6,1)
      \shortintertext{that represents the positions that the 1st element takes after $n$\ transforms, ending in 1 to represent completion of the cycle.  by "popping" elements from the front and "pushing" them to the rear, we can generate the remaining orderings:}
          p_2 &= (4,5,3,6,1,2)\\
          p_4 &= (5,3,6,1,2,4)\\
          p_5 &= (3,6,1,2,4,5)\\
          p_3 &= (6,1,2,4,5,3)\\
          p_6 &= (1,2,4,5,3,6)
      \end{align*}
      Note that with $n=6$\ elements there are $k=6$\ such orderings.  With $n=5$\ elements there can only be $k\leq n = 5$\ such orderings, since each ordering must have a unique final element.  Thus it is not possible to construct a six stanza form, but it would be possible to construct five:
      \begin{align*}
         p_1 &= (2,4,5,3,1) \\
         p_2 &= (4,5,3,1,2) \\
         p_4 &= (5,3,1,2,4) \\
         p_5 &= (3,1,2,4,5) \\
         p_3 &= (1,2,4,5,3)
      \shortintertext{which results in the permutation matrix}
         P &= \begin{Mat}{5} 0 & 0 & 1 & 0 & 0 \\
                             1 & 0 & 0 & 0 & 0 \\
                             0 & 0 & 0 & 0 & 1 \\
                             0 & 1 & 0 & 0 & 0 \\
                             0 & 0 & 0 & 1 & 0 \end{Mat}
      \shortintertext{verify:}
         \Vn{s}    &= \begin{Mat}{5} A & B & C & D & E \end{Mat}^T \\
         P\Vn{s}   &= \begin{Mat}{5} C & A & E & B & D \end{Mat}^T \\
         P^2\Vn{s} &= \begin{Mat}{5} E & C & D & A & B \end{Mat}^T \\
         P^3\Vn{s} &= \begin{Mat}{5} D & E & B & C & A \end{Mat}^T \\
         P^4\Vn{s} &= \begin{Mat}{5} B & D & A & E & C \end{Mat}^T \\
         P^5\Vn{s} &= \begin{Mat}{5} A & B & C & D & E \end{Mat}^T = \Vn{s}
      \end{align*}
    }
    \end{enumerate}
    ~\\
    \item
        Remember we were able to express rotations and reflections, which are geometric transformations, using a linear transformation $T$, the coefficient matrix corresponding to the transformation $(x,y)\to(x',y')$.
    \begin{enumerate}[label=(\alph*)]  
      \item \Que{
      What problem do you encounter with translation $(x,y)\to (x+h,y+k)$?
      }
      \Ans{
          This fails to retain addition.  Let $\Vn{x}=\Ve{x_1,x_2}\in \mathbb{R}^2$, Define $T:\mathbb{R}^2\to\mathbb{R}^2$\ by $T(\Ve{x_1,x_2})=\Ve{x_1+h,x_2+k}$.
          \begin{align*}
             T(\Vn{x}) &= \Ve{x_1+h,x_2+k}\\
             T(\Vn{y}) &= \Ve{y_1+h,y_2+k}\\
             T(\Vn{x}) + T(\Vn{y}) &= \Ve{x_1+h,x_2+k} + \Ve{y_1+h,y_2+k} = \Ve{x_1+y_1+2h,x_2+y_2+2k}\\
             T(\Vn{x}+\Vn{y}) &= T(\Ve{x_1+y_1,x_2+y_2}) = \Ve{(x_1+y_1)+h,(x_2+y_2)+k} \\
             T(\Vn{x}+\Vn{y}) &\not = T(\Vn{x}) + T(\Vn{y})
          \end{align*}
      }      
      To handle this problem, we introduce homogeneous coordinates.  We let the vector $(x_1,y_1)\in\mathbb{R}^2$\ correspond to the vector $(x,y,1)$, and conversely.  (In effect, we're projecting the $xy$-plane onto the plane $z=1$)
      \item \Que {
      Find $M$, the matrix corresponding to the translation $(x,y,1)\to(x+h,y+k,1)$.  
      }
      \Ans{
      \begin{align*}
          M &= \begin{Mat}{3} 1 & 0 & h \\
                              0 & 1 & k \\
                              0 & 0 & 1 \end{Mat}
          \shortintertext{Verify:}
          M\Vn{x} &= \begin{Mat}{3} 1 &  0 &  h \\
                                    0 &  1 &  k \\
                                    0 &  0 &  1 \end{Mat}
                     \begin{Mat}{1} x \\ y \\ 1 \end{Mat}
                   =
                     \begin{Mat}{1} x+h \\ y+k \\ 1 \end{Mat}
      \end{align*}
      }
      \newpage
      \item \Que {
      Let $T=\begin{Mat}{3} a_{11} & a_{12} & a_{13} \\
                            a_{21} & a_{22} & a_{23} \\
                            0      & 0      & 1 \end{Mat}$.  Consider the square with opposite vertices at $(0,0)$\ and $(1,1)$.  Find where each of the four vertices of the square ends up when the linear transformation $M$\ is applied to each of them.
      }
      \Ans{
         Let $v_1=(0,0)\to \Ve{0,0,1}, v_2=(1,0)\to\Ve{1,0,1}, v_3=(0,1)\to\Ve{0,1,1}, v_4=(1,1)\to\Ve{1,1,1}$.
         \begin{align*}
             Tv_1 &= \begin{Mat}{3} a_{11} & a_{12} & a_{13} \\
                                    a_{21} & a_{22} & a_{23} \\
                                    0      & 0      & 1 \end{Mat}
                     \begin{Cmat}{1} 0 \\ 0 \\ 1 \end{Cmat}
                   = \begin{Cmat}{1} 0a_{11} + 0a_{12} + 1a_{13} \\
                                    0a_{21} + 0a_{22} + 1a_{23} \\
                                    0 + 0 + 1 \end{Cmat}
                   = \begin{Cmat}{1} a_{13} \\ a_{23} \\ 1 \end{Cmat} \\
             Tv_2 &= \begin{Mat}{3} a_{11} & a_{12} & a_{13} \\
                                    a_{21} & a_{22} & a_{23} \\
                                    0      & 0      & 1 \end{Mat}
                     \begin{Cmat}{1} 1 \\ 0 \\ 1 \end{Cmat}
                   = \begin{Cmat}{1} 1a_{11} + 0a_{12} + 1a_{13} \\
                                    1a_{21} + 0a_{22} + 1a_{23} \\
                                    0 + 0 + 1 \end{Cmat} 
                   = \begin{Cmat}{1} a_{11}+a_{13} \\ a_{21}+a_{23} \\ 1 \end{Cmat}\\
             Tv_3 &= \begin{Mat}{3} a_{11} & a_{12} & a_{13} \\
                                    a_{21} & a_{22} & a_{23} \\
                                    0      & 0      & 1 \end{Mat}
                     \begin{Cmat}{1} 0 \\ 1 \\ 1 \end{Cmat}
                   = \begin{Cmat}{1} 0a_{11} + 1a_{12} + 1a_{13} \\
                                    0a_{21} + 1a_{22} + 1a_{23} \\
                                    0 + 0 + 1 \end{Cmat} 
                   = \begin{Cmat}{1} a_{12}+a_{13} \\ a_{22}+a_{23} \\ 1 \end{Cmat}\\
             Tv_4 &= \begin{Mat}{3} a_{11} & a_{12} & a_{13} \\
                                    a_{21} & a_{22} & a_{23} \\
                                    0      & 0      & 1 \end{Mat}
                     \begin{Cmat}{1} 1 \\ 1 \\ 1 \end{Cmat}
                   = \begin{Cmat}{1} 1a_{11} + 1a_{12} + 1a_{13} \\
                                    1a_{21} + 1a_{22} + 1a_{23} \\
                                    0 + 0 + 1 \end{Cmat} 
                   = \begin{Cmat}{1} a_{11}+a_{12}+a_{13} \\ a_{21}+a_{22}+a_{23} \\ 1 \end{Cmat}                          
         \end{align*}
      }
      \item \Que {
      Find the area of the resulting quadrilateral. 
      }
      \Ans{
          Let $\Vn{w}=\Line{v_1v_2}=v_2-v_1=\Ve{a_{11},a_{21},0}$, and $\Vn{x}=\Line{v_1v_3}=v_3-v_1=\Ve{a_{12},a_{22},0}$.  Since we are dealing with vectors in $\mathbb{R}^3$\ the cross product is defined, and the area of the quadrilateral formed coincides with the magnitude of the cross product $\Vn{w}\times\Vn{x}$:
          \begin{align*}
              A &= \norm{\Vn{w}\times\Vn{x}} = \norm{\begin{Mat}{1} a_{11} \\ a_{21} \\ 0 \end{Mat} \times
                                                     \begin{Mat}{1} a_{12} \\ a_{22} \\ 0 \end{Mat}}
                = \begin{vmatrix} i & j & k \\ a_{11} & a_{21} & 0 \\ a_{12} & a_{21} & 0 \end{vmatrix} \\
                &= \norm{0i-0j+(a_{11}a_{22}-a_{12}a_{21})k}
                 = \sqrt{0^2+0^2+(a_{11}a_{22}-a_{12}a_{21})^2}\\
                 &= \underline{a_{11}a_{22}-a_{12}a_{21}}
          \end{align*}
      }
      \item \Que{
      Suppose that when $T$\ is applied to a unit square, the transformed square has area $0$.  Does $T=0$\ (the $3\times 3$\ matrix of all zeros)?  Prove, or give a counterexample.
      }
      \Ans{
         Not necessarily.  counterexample:
         \begin{align*}
             T    &= \begin{Mat}{3} 0 & 0 & 1 \\ 0 & 0 & 1 \\ 0 & 0 & 1 \end{Mat} \\
             Tv_1 &= Tv_2 = Tv_3 = \begin{Mat}{1} 1 \\ 1 \\ 1 \end{Mat}
          %   Tv_1 &= T\begin{Mat}{1} 0 \\ 0 \\ 1 \end{Mat} = \begin{Mat}{1} 1 \\ 1 \\ 1 \end{Mat} \\
          %   Tv_2 &= T\begin{Mat}{1} 1 \\ 0 \\ 1 \end{Mat} = \begin{Mat}{1} 1 \\ 1 \\ 1 \end{Mat} \\
          %   Tv_3 &= T\begin{Mat}{1} 0 \\ 1 \\ 1 \end{Mat} = \begin{Mat}{1} 1 \\ 1 \\ 1 \end{Mat} \\
          %   Tv_3 &= T\begin{Mat}{1} 1 \\ 1 \\ 1 \end{Mat} = \begin{Mat}{1} 1 \\ 1 \\ 1 \end{Mat}
         \end{align*}
         We can see that the area of the transformed rectangle is $(1-1)\times(1-1) = 0$.
      }
    \end{enumerate}
    %~\\
    \newpage
    \item
        Given a matrix $M$, an eigenvalue-eigenvector pair is a number $\lambda$\ and vector $\Vn{v}$\ where $M\Vn{v}=\lambda\Vn{v}$.  $\Vn{v}$\ must be a non-zero vector; however $\lambda$\ could be zero.  In the following, assume $M$\ is a $2\times 2$\ matrix with distinct real eigenvalues $\lambda_1, \lambda_2$\ and corresponding eigenvectors $\Vn{v}_1, \Vn{v}_2$.  Assume $0<\norm{\lambda_1}<1<\lambda_2$, and that $\Vn{v}_1,\Vn{v}_2$\ span $\mathbb{R}^2$.
    \begin{enumerate}[label=(\alph*)]
    \item \Que{
        Since $\lambda_1,\Vn{v}_1$\ is an eigenvalue-eigenvector pair, we have $M\Vn{v}_1=\lambda_1\Vn{v}_1$.  Describe what this means geometrically. 
    }
    \Ans{
        If there exists such a pair, it means that applying the linear transformation corresponding to matrix $M$\ to the eigenvector $\Vn{v}_1$\ results in a vector $\Vn{v}_1^\prime$\ that is the same direction as $\Vn{v}_1$, scaled by $\lambda\in\mathbb{R}$. 
    }
    \item \Que{
        Prove or disprove: $c\Vn{v}_1$\ is an eigenvector for any real number $c$.
    }
    \Ans{ 
      Since we know $\Vn{v}_1$\ is an eigenvector, we know that $M\Vn{v}_1=\lambda_1\Vn{v}_1$.  Since scalar multiplication is distributive, it follows that $M(c\Vn{v}_1) = cM\Vn{v}_1 = (cM)\Vn{v}_1 = (c\lambda_1)\Vn{v}_1$\ which is an eigenvalue-eigenvector pair for the matrix $cM$.
    }
    \item \Que{
        Evaluate: $M^n\Vn{v}_1$\ and $M^n\Vn{v}_2$.
    }
    \Ans{
       \begin{minipage}[m]{0.4\textwidth}
       \begin{align*}
           M^n\Vn{v}_1 &= \lambda_1 M^{n-1}\Vn{v}_1 \\
                       &= \lambda_1^2 M^{n-2}\Vn{v}_1 \\
                       &= ~~~\vdots \\
                       &= \lambda_1^n\Vn{v}_1
       \end{align*}
       \end{minipage}
       \begin{minipage}[m]{0.4\textwidth}
       \begin{align*}
           M^n\Vn{v}_2 &= \lambda_1 M^{n-1}\Vn{v}_2 \\
                       &= \lambda_1^2 M^{n-2}\Vn{v}_2 \\
                       &= ~~~\vdots \\
                       &= \lambda_1^n\Vn{v}_2
       \end{align*}
       \end{minipage}
    }
    \item \Que{
        Let $\Vn{x}$\ be any vector in $\mathbb{R}^2$.  Evaluate: $M^n\Vn{x}$.
    }
    \Ans{
       Since eigenvectors $\Vn{v}_1,\Vn{v}_2$\ span $\mathbb{R}^2$, let $\Vn{x}=x_1\Vn{v}_1+x_2\Vn{v}_2$\ for some $x_1,x_2\in\mathbb{R}$.
       \begin{align*}     
           M\Vn{x}   &= M(x_1\Vn{v}_1+x_2\Vn{v}_2) \\
                     &= x_1M\Vn{v}_1 + x_2M\Vn{v}_2 \\
                     &= x_1\lambda_1\Vn{v}_1 + x_2\lambda_2\Vn{v}_2 \\
           M^2\Vn{x} &= M(x_1\lambda_1\Vn{v}_1 + x_2\lambda_2\Vn{v}_2) \\
                     &= x_1\lambda_1^2\Vn{v}_1 + x_2\lambda_2^2\Vn{v}_2 \\
                     & ~~ \vdots \\
           M^n\Vn{x} &= x_1\lambda_1^n\Vn{v}_1 + x_2\lambda_2^n\Vn{v}_2
       \end{align*}
    }
    \item \Que{
        One way to find the largest eigenvalue ($\lambda_2$\ in this case) and its corresponding eigenvector is the following:  Pick any non-zero vector $\Vn{x}$, and find $M^{n+1}\Vn{x}$\ and $M^n\Vn{x}$\ for a sufficiently large value of $n$.  
        Explain why $\lambda_2\approx \frac{\norm{M^{n+1}\Vn{x}}}{\norm{M^n\Vn{x}}}$.   
    }
    \Ans{
       Since a linear transformation will produce a uniform scaling across all eigenvectors transformed, and any arbitrary vector can be written as a linear combination of the eigenvectors, and the non-dominant eigenvalues are relatively small ($\norm{\lambda_1}\leq 1$\ in this case):
       \begin{align*}
           \Vn{x} &= x_1\Vn{v_1}+x_2\Vn{v_2} \\
           M\Vn{x} &= M(x_1\Vn{v_1}+x_2\Vn{v_2}) = x_1 M \Vn{v}_1 + x_2 M \Vn{v}_2 = x_1\lambda_1\Vn{v}_1+x_2\lambda_2\Vn{v}_2\\
           M^n\Vn{x} &= x_1\lambda_1^n\Vn{v}_1 + x_2\lambda_2^n\Vn{v}_2 \approx x_2\lambda_2^n\Vn{v}_2
        \shortintertext{since $\lambda_1^n\to 0$\ for sufficiently large $n$. Thus}
        \frac{M^{n+1}\Vn{x}}{M^n\Vn{x}} &\approx \frac{x_2\lambda_2 \lambda_2^n\Vn{v}_2}{x_2\lambda_2^n\Vn{v}_2}\\
                                        &\approx \lambda_2
       \end{align*}        
    }
    \newpage
    \item \Que{
        Let $M=\begin{Mat}{2} 2 & 1 \\ 0 & 1 \end{Mat}$.  Find $M^8, M^9$, and an approximation for $\lambda_2$\ and a corresponding eigenvector $\Vn{v}_2$.
    }
    \Ans{
        Let $\Vn{x}=\Ve{1,0}$.
        \begin{align*}
          M^1 &= \begin{Mat}{2}  2 &     1 \\ 0 & 1 \end{Mat}, ~~~
          M^2 = \begin{Mat}{2}   4 &     3 \\ 0 & 1 \end{Mat}, ~~~
          M^3 = \begin{Mat}{2}   8 &     7 \\ 0 & 1 \end{Mat}\\
          & ~~~~~~\vdots \\
          M^n &= \begin{Mat}{2} 2^n & 2^n-1 \\ 0 & 1 \end{Mat} \\
          M^8 &= \begin{Mat}{2} 256 & 255 \\ 0 & 1 \end{Mat} \\
          M^9 &= \begin{Mat}{2} 512 & 511 \\ 0 & 1 \end{Mat} \\
          M^8\Vn{x} &= \Ve{256\cdot 1 + 255\cdot 0, 0\cdot 1 + 1\cdot 0}
                    = \Ve{256,0} \\
          M^9\Vn{x} &= \Ve{512\cdot 1+ 511\cdot 0, 0\cdot 1 + 1\cdot 0}
                    = \Ve{512,0}\\
          \norm{M^8\Vn{x}} &= \sqrt{256^2+0^2} = 256\\
          \norm{M^9\Vn{x}} &= \sqrt{512^2+0^2} = 512\\
          \frac{\norm{M^9\Vn{x}}}{\norm{M^8\Vn{x}}}&=\frac{512}{256}= 2 
        \end{align*}
        Thus $\lambda_2\approx 2$.  Solving $M\Vn{v}_2=\lambda_2\Vn{v}_2$\ for $\Vn{y}=\Vn{v}_2$:
        \begin{align*}
            M\Vn{y} &= \lambda_2\Vn{y} = 2\Vn{y}\\
            \begin{Mat}{1} 2y_1 + y_2 \\  y_2 \end{Mat} &= \begin{Mat}{1} 2y_1 \\ 2y_2 \end{Mat} \\
            2y_1 + y_2 &= 2y_1 \\
            y_2 &= 0\\
            y_1 &= anything \cdots
        \end{align*}
        Thus we see an eigenvector $\Vn{v}_2 = \Vn{y} = \Ve{1,0}$ corresponds to $\lambda_2=2$.
    }
    \end{enumerate}
    %~\\
    \newpage
    \item Answer the following questions.
    \begin{enumerate}[label=(\alph*)]
    \item \Que{
        Solve the following system, parameterizing as necessary.
        \begin{align*}
             3x+2y-4z+w &= 0 \\
             x-4y+z+2w  &= 0 \\
             x+10y-6z-3w&= 0 \\
             2x+y-4z-5w &= 0
        \end{align*}
    }
    \Ans{
    First, put the corresponding coefficient matrix into row echelon form:
    \begin{align*}
        &~~~~~~R_1-R_4\to R_1\\
        &~~~~~~R_2-R_3\to R_2\\
        &~~~~~~R_3-R_2\to R_3~~~~~~~~~~~~~~~~~~5R_3+14R_4\to R_3\\
        &~~~~~~R_4-(R_2+R_3)\to R_4~~~~~~~~(R_2+R_3)/3\to R_4\\
        \begin{Mat}{4} 3 &  2 & -4 &  1 \\ 
                       1 & -4 &  1 &  2 \\ 
                       1 & 10 & -6 & -3 \\ 
                       2 &  1 & -4 & -5 \end{Mat}
        &\to
        \begin{Mat}{4} 1 &   1 &  0 &  6 \\
                       0 & -14 &  7 &  5 \\
                       0 &  14 & -7 & -5 \\
                       0 &  -5 &  1 & -4 \end{Mat}
        \to
        \begin{Mat}{4} 1 &   1 &  0 &  6 \\
                       0 & -14 &  7 &  5 \\
                       0 &   0 & -7 &-27 \\
                       0 &   0 &  0 &  0 \end{Mat}
        \shortintertext{To parameterize, let $7s=w$.}
        -7z-189s &= 0    \\
               z &= -27s \\
        -14y + 7z +5 w &= 0 \\
                  -14y &= -7(-27s)+5(7s) \\
                     y &= -\frac{27}{2}s - \frac{5}{2}s = -16s \\
            x + y + 6w &= 0 \\
                     x &= -(-16s) -6(7s) = (16-42)s = -26s  
    \end{align*}
    Thus the solution is the line $S=\{s\Ve{-26,-16,-27,7} : s\in\mathbb{R}\}$.
    }
    \newpage
    \item \Que{
        Let $\mathbb{A}$\ be the set of polynomials of the form $ax^2+bx+c$, where $a,b,c\in\mathbb{R}$, where we define addition and scalar multiplication using the standard rules of polynomial arithmatic.  Prove or disprove: $\mathbb{A}$\ is a vector space.
    }
    \Ans{
      Let $A_1,A_2,A_3 \in \mathbb{A}$\ such that $A_1=a_1x^2+b_1x+c_1, A_2=a_2x^2+b_2x+c_2, A_3=a_3x^2+b_3x+c_3$, and let $z,w \in \mathbb{R}$.
      \begin{align*}
        \shortintertext{the set is closed under addition:}
        A_1 + A_2 &= (a_1x^2+b_1x+c_1)+(a_2x^2+b_2x+c_2) = (a_1+a_2)x^2 + (b_1+b_2)x+(c_1+c_2) \in \mathbb{A}
        \shortintertext{the set is closed under scalar multiplication:}
        zA_1 &= z(a_1x^2+b_1x+c_1) = (za_1)x^2+(zb_1)x+(zc_1) \in \mathbb{A}
        \shortintertext{the set of commutative:}
        A_1+A_2 &= (a_1x^2+b_1x+c_1)+(a_2x^2+b_2x+c_2)   = (a_1+a_2)x^2 + (b_1+b_2)x+(c_1+c_2) \\
                &= (a_2+a_1)x^2 + (b_2+b_1)x + (c_2+c_1) = (a_2x^2+b_2x+c_2)+(a_1x^2+b_1x+c_1) \\
                &= A_2+A_1
        \shortintertext{the set is associative:}
        (A_1+A_2)+A_3 &= ((a_1+a_2)x^2 + (b_1+b_2)x+(c_1+c_2)) + (a_3x^2+b_3x+c_3) \\
                      &= (a_1+a_2+a_3)x^2 + (b_1+b_2+b_3)x + (c_1+c_2+c_3) \\
                      &= (a_1x^2+b_1x+c_1)+((a_2+a_3)x^2+(b_2+b_3)x+(c_2+c_3)) \\
                      &= A_1 + (A_2+A_3) 
         \shortintertext{the set contains a zero vector such that $A_1+\Vn{0}=A_1$:}
         \Vn{0} &= \Ve{0,0,0} = 0x^2+0x+0 = 0 \\
         A_1+\Vn{0} &= (a_1+0)x^2 + (b_1+0)x + (c_1+0) = a_1x^2 + b_1x+c_1 = A_1
         \shortintertext{the set contains additive inverses for all members:}
         A_1^\prime &= (-1)A_1 = -a_1x^2-b_1x-c_1\\
         A_1 + A_1^\prime &= (a_1-a_1)x^2+(b_1-b_1)x+(c_1-c_1) = 0x^2+0x+0 = \Vn{0} = 0 \\
         \shortintertext{multiplication by 1 is idempotent:}
         1A_1 &= 1(a_1x^2+b_1x+c_1) = a_1x^2+b_1x+c_1 = A_1
         \shortintertext{the set is associative of scalar multiplication:}
         z(wA_1) &= z(wa_1x^2+wb_1x+wc_1) = (zw)a_1x^2+(zw)b_1x+(zw)c_1 = (zw)(a_1x^2+b_1x+c_1)\\
                 &= (zw)(A_1)
         \shortintertext{the set is distributive of scalar over vector:}
         z(A_1+A_2) &= z((a_1+a_2)x^2 + (b_1+b_2)x+(c_1+c_2)) = z(a_1+a_2)x^2+z(b_1+b_2)x+z(c_1+c_2)\\
                    &= za_1x^2+za_2x^2+zb_1x+zb_2x+zc_1+zc_2 \\
                    &= z(a_1x^2+b_1x+c_1)+z(a_2x^2+b_2x+c_2) \\
                    &= zA_1+zA_2
         \shortintertext{the set is distributive of vector over scalar:}
         (z+w)A_1 &= (z+w)(a_1x^2+b_1x+c_1) = (z+w)a_1x^2 + (z+w)b_1x + (z+w)c_1 \\ 
                  &= za_1x^2+wa_1x^2+zb_1x+wb_1x+zc_1+wc_1 \\
                  &= z(a_1x^2+b_1x+c_1)+w(a_1x^2+b_1x+c_1)\\
                  &= zA_1 + wA_1
         \shortintertext{thus the set is a vector space.}
       \end{align*} 
    }
    
    \end{enumerate}
\end{enumerate} 
\end{document}  